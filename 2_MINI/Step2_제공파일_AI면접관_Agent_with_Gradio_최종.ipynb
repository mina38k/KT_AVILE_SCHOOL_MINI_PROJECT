{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Step1_AI면접관 Agent v1.0**"],"metadata":{"id":"mSB2IiVH8B1v"}},{"cell_type":"markdown","metadata":{"id":"zU-xxYwejwGR"},"source":["## **1. 환경준비**"]},{"cell_type":"markdown","metadata":{"id":"CdcBWhy_F_Hm"},"source":["### (1) 구글 드라이브"]},{"cell_type":"markdown","source":["#### 1) 구글 드라이브 폴더 생성\n","* 새 폴더(project_genai)를 생성하고\n","* 제공 받은 파일을 업로드"],"metadata":{"id":"xUOpvAJGGJnL"}},{"cell_type":"markdown","source":["#### 2) 구글 드라이브 연결"],"metadata":{"id":"4jUC5td4GLEF"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"tEfLUT6ZGEJi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747014379617,"user_tz":-540,"elapsed":2250,"user":{"displayName":"김민아","userId":"03129000200387278609"}},"outputId":"0bb47a52-abb5-458b-fbfa-b098520c28d7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### (2) 라이브러리"],"metadata":{"id":"PepxmQuiGzkX"}},{"cell_type":"code","source":["!pip install -r /content/drive/MyDrive/project_genai/requirements.txt -q"],"metadata":{"id":"TwO3_Qx4PlM-","executionInfo":{"status":"ok","timestamp":1747014386861,"user_tz":-540,"elapsed":4030,"user":{"displayName":"김민아","userId":"03129000200387278609"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PS5BhycUFUMI"},"source":["### (3) OpenAI API Key 확인\n","* api_key.txt 파일에 다음의 키를 등록하세요.\n","    * OPENAI_API_KEY\n","    * NGROK_AUTHTOKEN"]},{"cell_type":"code","source":["import os\n","\n","def load_api_keys(filepath=\"api_key.txt\"):\n","    with open(filepath, \"r\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if line and \"=\" in line:\n","                key, value = line.split(\"=\", 1)\n","                os.environ[key.strip()] = value.strip()\n","\n","path = '/content/drive/MyDrive/project_genai/'\n","# API 키 로드 및 환경변수 설정\n","load_api_keys(path + 'api_key.txt')"],"metadata":{"id":"AaZBGfeWNMRE","executionInfo":{"status":"ok","timestamp":1747014393224,"user_tz":-540,"elapsed":18,"user":{"displayName":"김민아","userId":"03129000200387278609"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(os.environ['OPENAI_API_KEY'][:30])"],"metadata":{"id":"GqSUhiv8wKxh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747014395152,"user_tz":-540,"elapsed":37,"user":{"displayName":"김민아","userId":"03129000200387278609"}},"outputId":"13eba8d2-1850-46de-8b2a-52519b9a46ac"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["sk-proj-hzRpWhet6v1j6AyC_oUyrM\n"]}]},{"cell_type":"markdown","source":["## **2. App.py**\n","\n","* 아래 코드에, Step1 혹은 고도화 된 Step2 파일 코드를 붙인다.\n","    * 라이브러리\n","    * 함수들과 그래프\n","* Gradio 코드는 그대로 사용하거나 일부 수정 가능"],"metadata":{"id":"ULAOaRHmShq1"}},{"cell_type":"code","source":["%%writefile app.py\n","\n","####### 여러분의 함수와 클래스를 모드 여기에 붙여 넣읍시다. #######\n","## 1. 라이브러리 로딩 ---------------------------------------------\n","import pandas as pd\n","import numpy as np\n","import os\n","import openai\n","import random\n","import ast\n","import fitz\n","from docx import Document as DocxDocument\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","from typing import Annotated, Literal, Sequence, TypedDict, List, Dict\n","from langchain import hub\n","from langchain_core.messages import BaseMessage, HumanMessage\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n","from langchain_core.documents import Document\n","from langchain_openai import ChatOpenAI\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_community.vectorstores import Chroma\n","from langchain.output_parsers import CommaSeparatedListOutputParser, PydanticOutputParser\n","from langgraph.graph import StateGraph, START, END\n","\n","from pydantic import BaseModel\n","\n","## ---------------- 1단계 : 사전준비 ----------------------\n","\n","# 1) 파일 입력 --------------------\n","def extract_text_from_file(file_path: str) -> str:\n","    ext = os.path.splitext(file_path)[1].lower()\n","    if ext == \".pdf\":\n","        doc = fitz.open(file_path)\n","        text = \"\\n\".join(page.get_text() for page in doc)\n","        doc.close()\n","        return text\n","    elif ext == \".docx\":\n","        doc = DocxDocument(file_path)\n","        return \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n","    else:\n","        raise ValueError(\"지원하지 않는 파일 형식입니다. PDF 또는 DOCX만 허용됩니다.\")\n","\n","# 2) State 선언 --------------------\n","class StrategySection(BaseModel):\n","    질문방향: str\n","    예시질문: list[str]\n","\n","class InterviewStrategy(BaseModel):\n","    경력_및_경험: StrategySection\n","    동기_및_커뮤니케이션: StrategySection\n","    논리적_사고: StrategySection\n","\n","class Evaluation(BaseModel):\n","    질문과의_관련성: str\n","    답변의_구체성: str\n","\n","class InterviewState(TypedDict):\n","    # 고정 정보\n","    resume_text: str\n","    resume_summary: str\n","    resume_keywords: List[str]\n","    question_strategy: InterviewStrategy\n","\n","    # 인터뷰 로그\n","    current_question: str\n","    current_answer: str\n","    current_strategy: str\n","    conversation: List[Dict[str, str]]\n","    evaluation : List[Evaluation]\n","    strategies: List[str]\n","    next_step : str\n","    #######################################################\n","    evaluation_ok: bool\n","    re_evaluated: bool\n","    #######################################################\n","\n","    ## 1. 수정 부분\n","    feedback_report: str\n","\n","# 3) resume 분석 --------------------\n","def analyze_resume(state: InterviewState) -> InterviewState:\n","    # 여기에 코드를 완성합니다.\n","\n","    llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n","\n","    summary_prompt = PromptTemplate(\n","        input_variables=[\"resume\"],\n","        template=\"\"\"\n","        {resume}를 읽고,\n","        개인화된 질문을 뽑기 위한 이력서 핵심 내용만 보고서 형태로 추출해줘.\n","        앞뒤 부가내용 없이\"\"\"\n","    )\n","    summary_chain = summary_prompt | llm | StrOutputParser()\n","\n","    keyword_prompt = PromptTemplate(\n","        input_variables=[\"resume\"],\n","        template=\"\"\"\n","        {resume}를 읽고,\n","        주요 키워드만 쉼표로 구분해서 10개 내외로 뽑아줘.\n","        부가설명 없이 키워드만.\"\"\"\n","    )\n","    keyword_chain = keyword_prompt | llm | StrOutputParser()\n","\n","\n","    resume_summary = summary_chain.invoke({\"resume\": state['resume_text']})\n","\n","    keywords_str = keyword_chain.invoke({\"resume\": state['resume_text']})\n","    resume_keywords = [kw.strip() for kw in keywords_str.split(\",\")]\n","\n","    # return 코드는 제공합니다.\n","    return {\n","        **state,\n","        \"resume_summary\": resume_summary,\n","        \"resume_keywords\": resume_keywords,\n","    }\n","\n","# 4) 질문 전략 수립 --------------------\n","def generate_question_strategy(state: InterviewState) -> InterviewState:\n","    # 여기에 코드를 완성합니다.\n","    llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n","\n","    prompt = PromptTemplate(\n","            input_variables=[\"resume_summary\", \"resume_keywords\"],\n","            template=\"\"\"\n","            [이력서 요약]\n","            {resume_summary}\n","\n","            [주요 키워드]\n","            {resume_keywords}\n","\n","            -- 면접 전략 생성\n","            - 다음 3개 영역별로 JSON 형식 생성:\n","            1. 경력 및 경험: 역할/성과 중심 질문\n","            2. 동기 및 커뮤니케이션: 가치관/소통능력 평가\n","            3. 논리적 사고: 문제해결 과정 평가\n","\n","            -- 출력 형식\n","            {{\n","              \"경력_및_경험\": {{\n","                \"질문방향\": \"...\",\n","                \"예시질문\": [\"...\", \"...\"]\n","              }},\n","              \"동기_및_커뮤니케이션\": {{\n","                \"질문방향\": \"...\",\n","                \"예시질문\": [\"...\", \"...\"]\n","              }},\n","              \"논리적_사고\": {{\n","                \"질문방향\": \"...\",\n","                \"예시질문\": [\"...\", \"...\"]\n","              }}\n","            }}\n","            \"\"\"\n","        )\n","\n","    # 체인 구성\n","    parser = PydanticOutputParser(pydantic_object=InterviewStrategy)\n","    chain = prompt | llm | parser\n","\n","    strategy = chain.invoke({\n","        \"resume_summary\": state['resume_summary'],\n","        \"resume_keywords\": state['resume_keywords']\n","    })\n","\n","\n","    # return 코드는 제공합니다.\n","    return {\n","        **state,\n","        \"question_strategy\": strategy\n","    }\n","\n","def makeState(resume_text: str) -> InterviewState:\n","  return {\n","      \"resume_text\": resume_text,\n","      \"resume_summary\": '',\n","      \"resume_keywords\": [],\n","      \"question_strategy\": {},\n","\n","      \"current_question\": '',\n","      \"current_answer\": '',\n","      \"current_strategy\": '',\n","      \"conversation\": [],\n","      \"evaluation\": [],\n","      \"strategies\": [],\n","      \"next_step\" : '',\n","      #######################################################\n","      \"evaluation_ok\": False,\n","       \"re_evaluated\": False,\n","      #######################################################\n","\n","      # 1. 수정 부분\n","      \"feedback_report\": '',\n","  }\n","\n","# 5) 1단계 하나로 묶기 --------------------\n","\n","def preProcessing_Interview(file_path: str) -> InterviewState:\n","    # 여기에 코드를 완성합니다.\n","    resume_text = extract_text_from_file(file_path)\n","    initial_state = makeState(resume_text)\n","\n","    analyzed_state = analyze_resume(initial_state)\n","    state = generate_question_strategy(analyzed_state)\n","\n","    strategy = state['question_strategy']\n","\n","    selected_question = strategy.경력_및_경험.예시질문[0]\n","\n","\n","    # return 코드는 제공합니다.\n","    return {\n","            **state,\n","            \"current_question\": selected_question,\n","            \"current_strategy\": \"경력 및 경험\"\n","            }\n","\n","\n","## ---------------- 2단계 : 면접 Agent ----------------------\n","\n","# 1) 답변 입력 --------------------\n","def update_current_answer(state: InterviewState, user_answer: str) -> InterviewState:\n","    return {\n","        **state,\n","        \"current_answer\": user_answer.strip()\n","    }\n","\n","# 2) 답변 평가 --------------------\n","def evaluate_answer(state: InterviewState) -> InterviewState:\n","    # 여기에 코드를 완성합니다.\n","    llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n","\n","    prompt = PromptTemplate(\n","            input_variables=[\"current_question\", \"current_answer\"],\n","            template=\"\"\"\n","            [질문]\n","            {current_question}\n","\n","            [답변]\n","            {current_answer}\n","\n","            -- 다음 항목에 대한 답변 평가\n","            - '상', '중', '하' 로 평가\n","            - 1. 질문과의 관련성\n","              - '상': 질문의 핵심 의도 정확히 부함하며, 전반적인 내용을 명확히 다룸\n","              - '중': 질문과 관련은 있지만 핵심 포인트가 부분적으로 누락됨\n","              - '하': 질문과 관련이 약하거나 엉뚱한 내용 중심\n","            - 2. 답변의 구체성\n","              - '상': 구체적인 사례, 데이터, 단계별 설명 등이 포함되어 명확히 근거를 제시함\n","              - '중': 일부 구체적 내용이 있으나 추가 설명이나 예시가 부족함\n","              - '하': 추상적이거나 모호한 표현만 사용되어 핵심 내용이 불분명함\n","\n","            -- 출력 형식\n","            {{\n","              \"질문과의_관련성\": \"...\",\n","              \"답변의_구체성\": \"...\"\n","            }}\n","            \"\"\"\n","        )\n","\n","    # 체인 구성\n","    parser = PydanticOutputParser(pydantic_object=Evaluation)\n","    chain = prompt | llm | parser\n","\n","    assessment = chain.invoke({\n","        \"current_question\": state['current_question'],\n","        \"current_answer\": state['current_answer']\n","    })\n","\n","    state['conversation'].append({\n","        \"question\": state['current_question'],\n","        \"answer\": state['current_answer']\n","    })\n","\n","\n","    state['evaluation'].append(assessment)\n","    state['strategies'].append(state['current_strategy'])\n","\n","    #######################################################\n","    state['evaluation_ok'] = (\n","        assessment.질문과의_관련성 == '상'\n","        and assessment.답변의_구체성    == '상'\n","    )\n","    if 're_evaluated' not in state:\n","        state['re_evaluated'] = False\n","    #######################################################\n","    # return 코드는 제공합니다.\n","\n","    return {\n","        **state\n","    }\n","\n","# 3) 인터뷰 진행 검토 --------------------\n","def decide_next_step(state: InterviewState) -> InterviewState:\n","    # 여기에 코드를 완성합니다.\n","\n","    keys = [key.replace(\"_\", \" \") for key in InterviewStrategy.__fields__.keys()]\n","    latest_eval = state['evaluation'][-1]\n","\n","    if (all(item in state['strategies'] for item in keys)):\n","      # log\n","      print(\"=\"*60)\n","      print(\"[decide_next_step] 🚩 모든 전략 영역을 커버했음\")\n","      print(\"=\"*60)\n","\n","      next_step = 'end'\n","\n","    elif (len(state['conversation']) >= 5):\n","      next_step = 'end'\n","\n","    elif ((latest_eval.질문과의_관련성 == '하') or (latest_eval.답변의_구체성 == '하')):\n","      # log\n","      print(\"=\"*60)\n","      print(\"[decide_next_step] 🚩 답변 평가가 '하'로 추가 질문을 생성합니다.\")\n","      print(\"=\"*60)\n","\n","      next_step = 'additional_question'\n","\n","    else:\n","      state['current_strategy'] = next(\n","          (k for k in keys if k not in state['strategies']),\n","          None)\n","\n","      # log\n","      print(\"=\"*60)\n","      print(f\"[decide_next_step] 🚩 질문 전략을 변경합니다. {state['current_strategy']}\")\n","      print(\"=\"*60)\n","\n","      next_step = 'additional_question'\n","\n","\n","    # return 코드는 제공합니다.\n","    return {\n","        **state,\n","        \"next_step\": next_step\n","    }\n","\n","# 4) 질문 생성 --------------------\n","question_db = [\n","    # 1. 경력 및 경험\n","    \"KT AI 연구소 인턴십에서 딥러닝 후처리 파이프라인 설계 시 가장 중점을 둔 기술적 요소는 무엇이었나요?\",\n","    \"OCR 성능을 12% 개선하는 과정에서 어떤 문제가 가장 도전적이었으며, 이를 어떻게 해결했나요?\",\n","    \"AI 면접관 시스템을 개발하면서 GPT와 FAISS를 연동한 방식에 대해 설명해 주세요.\",\n","    \"빅데이터 학생연합 기술부장 시절, 팀 리더로서 기술적 의사결정을 내린 경험이 있다면 설명해 주세요.\",\n","    \"부동산 가격 예측 프로젝트에서 공공데이터 활용 과정에서 겪은 어려움과 해결방안을 공유해 주세요.\",\n","    \"Streamlit을 활용한 프론트엔드 구성에서 사용자 경험(UX)을 어떻게 고려했는지 설명해 주세요.\",\n","    \"딥러닝 기반 교통량 예측 프로젝트에서 LSTM 모델을 선택한 이유와 성능 향상 전략은 무엇이었나요?\",\n","    \"Jenkins를 활용한 프로젝트 배포 경험이 있으신데, CI/CD 파이프라인 구축 시 고려한 핵심 요소는 무엇인가요?\",\n","    \"OpenCV를 활용한 이미지 전처리에서 가장 중요하게 작용한 필터나 알고리즘은 무엇이었나요?\",\n","    \"Tesseract OCR 결과가 불완전할 때, 후처리 모델이 이를 보정하는 흐름은 어떤 방식으로 작동했나요?\",\n","    \"알고리즘 테스트에서 B형(Pro) 등급을 취득하셨는데, 시험 대비에서 어떤 전략을 사용하셨나요?\",\n","    \"BERT 기반 문장 재구성 모델을 OCR 후처리에 적용할 때 어떤 기준으로 문장 단위를 정의했는지 설명해 주세요.\",\n","    \"OCR 전처리 과정에서 적용한 OpenCV 기법들 중 가장 성능 개선에 기여한 기법은 무엇이었고, 그 이유는 무엇인가요?\",\n","    \"OCR 결과의 품질 향상을 위해 전처리와 후처리 단계에서 각각 어떤 기술적 전략을 사용하셨나요?\",\n","    \"BERT 기반 후처리 모델을 학습할 때 가장 민감하게 반응했던 하이퍼파라미터는 무엇이었나요?\",\n","    \"OCR 텍스트가 비정형인 경우에도 BERT가 안정적으로 동작하게 하기 위해 어떤 사전 전처리를 적용하셨나요?\",\n","\n","    # 2. 동기 및 커뮤니케이션\n","    \"큰 규모의 조직을 선호하신다고 했는데, 스타트업과 비교하여 어떤 점이 본인의 성향과 잘 맞는다고 생각하시나요?\",\n","    \"문제 해결 중 스트레스를 받는 상황에서 커피나 독서로 기분 전환한다고 하셨는데, 실제 업무 중에도 효과가 있었던 사례가 있나요?\",\n","    \"개발자 친화적인 문화에 대해 언급하셨는데, 본인이 생각하는 이상적인 개발문화는 어떤 모습인가요?\",\n","    \"코드 리뷰의 중요성을 강조하셨는데, 본인이 리뷰를 주도했던 경험이 있다면 설명해 주세요.\",\n","    \"팀 내에서 커뮤니케이션이 잘 된 프로젝트와 그렇지 않았던 프로젝트를 비교해본다면 어떤 차이가 있었나요?\",\n","    \"전공 외의 내용을 다루는 업무가 주어졌을 때, 어떻게 접근하시고 어떤 식으로 학습하시나요?\",\n","    \"다른 개발자와의 코드 스타일 충돌이 있었던 경험이 있다면, 어떻게 조율하셨나요?\",\n","    \"자기주도 학습에 강하다고 하셨는데, 팀 프로젝트 내에서는 어떤 식으로 이를 조화시키셨나요?\",\n","    \"협업 시 Jira를 사용해보셨다고 했는데, 업무 분담과 진행 상황 공유를 어떻게 효율화하셨나요?\",\n","    \"업무에 몰입하지 못하는 상황에서도 성과를 낸 경험이 있다면 어떻게 극복했는지 이야기해 주세요.\",\n","\n","    # 3. 논리적 사고 및 문제 해결\n","    \"로컬에서는 문제없이 작동하던 서버 코드가 배포 시 에러가 발생한 원인을 어떻게 진단하고 해결하셨나요?\",\n","    \"메모리 상의 비트 단위까지 디버깅한 경험이 있으신데, 어떤 판단을 통해 그 수준까지 추적하게 되었나요?\",\n","    \"OCR 프로젝트에서 기존 시스템 대비 개선률을 정량적으로 판단한 기준은 무엇이었나요?\",\n","    \"LSTM 모델의 MAE를 15% 이하로 낮추는 과정에서 모델 구조 외에 데이터 전처리 측면의 개선이 있었다면요?\",\n","    \"Streamlit과 FAISS를 연동하여 이력서 기반 질문을 자동 생성할 때 데이터 검색 정확도를 어떻게 확보했나요?\",\n","    \"Flask API 개발 시 논리적 오류나 구조적 비효율을 발견하고 개선한 사례가 있다면 설명해 주세요.\",\n","    \"기술부장으로서 팀원 간 기술 수준 차이를 어떻게 인지하고 프로젝트에 반영했는지 설명해 주세요.\",\n","    \"정보처리기사 취득 이후 어떤 부분에서 이론이 실무에 도움이 되었는지 구체적으로 말씀해 주세요.\",\n","    \"알고리즘 문제 풀이에서 기억나는 가장 어려운 문제는 무엇이었고, 해결 과정에서 얻은 통찰은 무엇인가요?\",\n","    \"ORM 학습을 시작하셨다고 했는데, 기존 SQL Mapper(MyBatis)와 비교했을 때 어떤 장단점을 느끼셨나요?\"\n","\n","    # ai_qa.csv\n","    \"개발 중 알 수 없는 버그나 예상치 못한 에러를 해결했던 경험을 구체적으로 말씀해 주세요. 당시 사용했던 디버깅 방법이나 접근 방식을 포함해서 설명해 주세요.\",\n","    \"KT AI 연구소 인턴 당시 OCR 문서 처리 시스템을 고도화하셨다고 했는데, 본인이 맡은 역할과 개선 성과를 구체적으로 설명해 주세요.\",\n","    \"협업 프로젝트에서 팀원과의 의견 충돌이나 역할 충돌이 있었던 경험이 있나요? 그 상황에서 어떻게 소통하며 조율하셨는지 말씀해 주세요.\",\n","    \"본인이 생각하는 이상적인 팀워크란 무엇이고, 그런 팀을 위해 본인은 어떤 노력을 해왔나요?\",\n","    \"새로운 기술이나 도구를 배워야 했던 상황에서 어떻게 접근하고 학습하셨는지, 최근에 학습한 기술 중 하나를 예로 들어 말씀해 주세요.\",\n","    \"회사를 선택할 때 가장 중요하게 생각하는 기준은 무엇인가요?\",\n","    \"팀 내에서 맡은 역할이 본인의 강점과 어떻게 연결되었다고 생각하나요?\",\n","    \"OCR 성능을 개선하기 위해 어떤 기술 스택을 선택했으며, 그 이유는 무엇인가요?\",\n","    \"프로젝트에서 성능 지표는 어떤 기준으로 설정했고, 목표 달성은 어떻게 평가하셨나요?\",\n","    \"기술적 난관에 직면했을 때 어떻게 접근하고 해결하셨나요?\",\n","    \"팀 내에서 본인이 기술적으로 가장 많이 기여한 부분은 어떤 부분인가요?\",\n","    \"프로젝트 기간 내에 일정과 품질을 동시에 만족시키기 위해 어떤 전략을 사용하셨나요?\",\n","    \"새로운 기술을 프로젝트에 도입할 때 어떤 기준으로 기술 스택을 선정하셨나요?\",\n","    \"데이터 파이프라인을 설계하면서 고려한 요소와 실제 적용한 방식은 무엇이었나요?\",\n","    \"자신이 개발한 기능이 사용자 혹은 내부 프로세스에 어떤 실질적 영향을 주었는지 설명해 주세요.\",\n","    \"프로젝트 초기 기획 단계에서 기술적 제안을 한 경험이 있다면 어떤 내용이었나요?\",\n","    \"협업 환경에서 Git이나 CI 도구를 사용하며 발생한 이슈를 어떻게 해결하셨나요?\",\n","    \"기획자나 디자이너와 협업하면서 생긴 기술적 오해를 어떻게 풀었는지 사례가 있다면 말씀해 주세요.\",\n","    \"팀 프로젝트 중 갈등이 생겼을 때 중재하거나 분위기를 전환한 경험이 있다면요?\",\n","    \"회의에서 자신의 기술적 의견이 반영되도록 설득한 과정이 있다면 공유해 주세요.\",\n","    \"다른 개발자의 코드 스타일을 존중하면서 협업한 구체적인 방법은 무엇이었나요?\",\n","    \"동료가 맡은 작업이 지연되었을 때 전체 일정 관점에서 어떻게 대응하셨나요?\",\n","    \"코드 리뷰 과정에서 팀원과의 의견 충돌을 조율한 경험이 있다면 공유해 주세요.\",\n","    \"기술적 설명을 비전공자나 실무 담당자에게 효과적으로 전달했던 경험이 있나요?\",\n","    \"협업 중 예상치 못한 일정 지연이 발생했을 때, 어떻게 대응하고 조율하셨나요?\",\n","    \"팀 프로젝트에서 리더와 팔로워 역할 중 어떤 것을 맡았고, 각기 어떤 점이 어려웠나요?\",\n","    \"Jira나 GitHub 등 협업 도구를 사용하면서 생긴 커뮤니케이션 노하우가 있다면 설명해주세요.\",\n","    \"디버깅 과정에서 일반적인 도구나 방법으로 해결되지 않았던 문제를 어떻게 해결하셨나요?\",\n","    \"시스템 병목 현상을 발견하고 해결한 경험이 있다면 어떤 접근을 하셨나요?\",\n","    \"성능 튜닝이 필요했던 상황에서 어떤 기준으로 병목을 진단하고 개선하셨나요?\",\n","    \"논리적으로 복잡한 문제를 단순하게 분해하여 해결한 경험이 있다면 말씀해 주세요.\",\n","    \"이전 버전과 비교하여 개선된 점을 수치나 구조적으로 설명할 수 있나요?\",\n","    \"비정형 데이터를 처리하는 과정에서 어떤 문제를 가장 먼저 발견하셨나요?\",\n","    \"오류가 반복적으로 발생했을 때, 원인을 어떻게 추적하고 분석하셨나요?\",\n","    \"다양한 해결 방법 중 현재 접근 방식을 선택하게 된 판단 근거는 무엇이었나요?\",\n","    \"이전 방식 대비 성능 향상을 논리적으로 증명할 수 있는 지표나 실험 결과가 있었나요?\",\n","    \"새로운 방법론을 시도했지만 성과가 미흡했던 사례가 있다면, 왜 그런 결과가 나왔다고 생각하시나요?\",\n","\n","]\n","\n","# Document 리스트로 변환\n","docs = [Document(page_content=q) for q in question_db]\n","\n","# 벡터 DB 정의\n","embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n","vectorstore = Chroma.from_documents(docs, embedding, persist_directory=\"chroma_db_2\")\n","\n","# Retriever 생성 - 상위 3개 유사질문\n","retriever = vectorstore.as_retriever(search_kwargs={\"k\":3})\n","\n","def generate_question(state: InterviewState) -> InterviewState:\n","    # 여기에 코드를 완성합니다.\n","    llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n","\n","    query_text = f\"{state['current_strategy']} {state['resume_keywords']}\"\n","    similar_docs = retriever.invoke(query_text)\n","    similar_questions = [doc.page_content for doc in similar_docs]\n","\n","    prompt = PromptTemplate(\n","            input_variables=[\"resume_summary\",\n","                             \"resume_keywords\",\n","                             \"current_strategy\",\n","                             \"current_question\",\n","                             \"current_answer\",\n","                             \"evaluation\",\n","                             \"similar_questions\"],\n","            template=\"\"\"\n","            질문 전략에 맞는 인터뷰 질문 1개를 생성해야 합니다.\n","            유사 질문을 꼭 참고하세요.\n","\n","            [질문전략]\n","            {current_strategy}\n","\n","            [유사 질문]\n","            {similar_questions}\n","\n","            이력서 요약, 키워드, 이전 질문과 답변, 평가를 기반으로\n","            지원자의 사고력, 문제 해결 방식,\n","            혹은 기술적 깊이를 더 확인할 수 있는 심화 인터뷰 질문 1개\n","            부가적인 말 없이 바로 질문하는 형식으로 생성\n","\n","            [이력서 요약]\n","            {resume_summary}\n","\n","            [키워드]\n","            {resume_keywords}\n","\n","            [이전 질문]\n","            {current_question}\n","\n","            [이전 답변]\n","            {current_answer}\n","\n","            [평가]\n","            {evaluation}\n","\n","            \"\"\"\n","        )\n","\n","    # 체인 구성\n","    chain = prompt | llm\n","\n","    question = chain.invoke({\n","        \"resume_summary\": state['resume_summary'],\n","        \"resume_keywords\": state['resume_keywords'],\n","        \"current_strategy\": state['current_strategy'],\n","        \"current_question\": state['current_question'],\n","        \"current_answer\": state['current_answer'],\n","        \"evaluation\": state['evaluation'],\n","        \"similar_questions\": similar_questions,\n","    })\n","\n","    # return 코드는 제공합니다.\n","\n","    return {\n","        **state,\n","        \"current_question\": question.content,\n","        \"current_answer\": \"\"\n","    }\n","\n","# 5) 인터뷰 피드백 보고서 --------------------\n","def summarize_interview(state: InterviewState) -> InterviewState:\n","    llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n","\n","    resume_summary = state.get(\"resume_summary\", \"\")\n","    resume_keywords = \", \".join(state.get(\"resume_keywords\", []))\n","    conversation = state.get(\"conversation\", [])\n","    evaluation = state.get(\"evaluation\", [])\n","\n","    # 인터뷰 로그 문자열 구성\n","    conversation_block = \"\"\n","    for i, (conv, eval_obj) in enumerate(zip(conversation, evaluation)):\n","        question = conv[\"question\"]\n","        answer = conv[\"answer\"]\n","        # Pydantic 모델의 속성은 dot notation으로 접근\n","        eval_text = f\"연관성: {eval_obj.질문과의_관련성}, 구체성: {eval_obj.답변의_구체성}\"\n","        conversation_block += f\"[질문 {i+1}] {question}\\n[답변 {i+1}] {answer}\\n[평가] {eval_text}\\n\\n\"\n","\n","    # 프롬프트 템플릿\n","    feedback_prompt = ChatPromptTemplate.from_template(\"\"\"\n","        당신은 AI 인터뷰 코치입니다.\n","        다음은 지원자와의 인터뷰 대화와 각 답변에 대한 평가입니다.\n","\n","        [이력서 요약]\n","        {resume_summary}\n","\n","        [이력서 키워드]\n","        {resume_keywords}\n","\n","        [인터뷰 로그 및 평가]\n","        {conversation_block}\n","\n","        위 내용을 바탕으로 다음 형식으로 자세한 피드백 보고서를 작성해 주세요:\n","        1. 전체적인 피드백 요약 (강점, 개선점 요약)\n","        2. 질문별 상세 피드백 (각 질문에 대한 평가와 개선 조언)\n","        3. 면접 대비를 위한 구체적인 개선 방향 및 연습 팁\n","\n","        각 항목은 구분된 제목과 함께 Markdown 형식으로 출력해 주세요.\n","        \"\"\")\n","\n","    # 프롬프트 인보크 실행\n","    formatted_prompt = feedback_prompt.invoke({\n","        \"resume_summary\": resume_summary,\n","        \"resume_keywords\": resume_keywords,\n","        \"conversation_block\": conversation_block.strip()\n","    })\n","\n","    response = llm.invoke(formatted_prompt)\n","\n","    ## 1. 수정 부분\n","    feedback_report = \"\\n### 인터뷰 피드백 보고서 ###\\n\" + response.content.strip()\n","    state['feedback_report'] = feedback_report\n","\n","    return state\n","\n","#######################################################\n","def re_evaluate_answer(state: InterviewState) -> InterviewState:\n","    print(\"재평가를 수행합니다.\")\n","\n","    # 무한 루프 방지를 위해 재평가 완료 플래그 설정\n","    state['re_evaluated'] = True\n","\n","    # 상태 전이: 재평가 완료 후 다음 단계로 진행\n","    if state.get('next_step') == 're_evaluate_answer':\n","        print(\"재평가 완료. 다음 단계로 진행합니다.\")\n","        state['next_step'] = 'decide_next_step'\n","    return state\n","\n","#######################################################\n","\n","# 6) Agent --------------------\n","# 분기 판단 함수\n","def route_next(state: InterviewState) -> Literal[\"generate\", \"summarize\"]:\n","    return \"summarize\" if state[\"next_step\"] == \"end\" else \"generate\"\n","#######################################################\n","def _eval_branch(state: InterviewState) -> Literal[\"next\", \"re\"]:\n","    eval_ok = state.get('evaluation_ok', False)\n","    re_eval = state.get('re_evaluated', False)\n","    if not eval_ok and not re_eval:\n","        return \"re\"\n","    return \"next\"\n","#######################################################\n","\n","# 그래프 정의 시작\n","builder = StateGraph(InterviewState)\n","\n","# 노드 추가\n","builder.add_node(\"evaluate_answer\", evaluate_answer)\n","builder.add_node(\"decide_next_step\", decide_next_step)\n","builder.add_node(\"generate_question\", generate_question)\n","builder.add_node(\"summarize_interview\", summarize_interview)\n","builder.add_node(\"re_evaluate_answer\", re_evaluate_answer) ####\n","\n","#######################################################\n","builder.add_conditional_edges(\"evaluate_answer\",_eval_branch,\n"," {\"next\":   \"decide_next_step\",\n","\"re\":     \"re_evaluate_answer\",})\n","\n","builder.add_edge(\"re_evaluate_answer\", \"decide_next_step\")\n","\n","builder.add_conditional_edges(\"decide_next_step\", route_next,\n","                          {\"summarize\": \"summarize_interview\",\n","                           \"generate\": \"generate_question\"}\n","                          )\n","#######################################################\n","\n","\n","# 노드 연결\n","builder.add_edge(START, \"evaluate_answer\")\n","builder.add_edge(\"summarize_interview\", END)\n","builder.add_edge(\"generate_question\", END)\n","\n","# 컴파일\n","graph = builder.compile()\n","\n","\n","# 그래프 그려보고 싶을때\n","# print(graph.get_graph().draw_mermaid())\n","# https://mermaid.live/\n","\n","#-------------------------------------------------------------------\n","\n","########### 다음 코드는 제공되는 gradio 코드 입니다.################\n","\n","import gradio as gr\n","import tempfile\n","\n","# 세션 상태 초기화 함수\n","def initialize_state():\n","    return {\n","        \"state\": None,\n","        \"interview_started\": False,\n","        \"interview_ended\": False,\n","        \"chat_history\": []\n","    }\n","\n","# 파일 업로드 후 인터뷰 초기화\n","def upload_and_initialize(file_obj, session_state):\n","    if file_obj is None:\n","        return session_state, \"파일을 업로드해주세요.\"\n","\n","    # Gradio는 file_obj.name 이 파일 경로야\n","    file_path = file_obj.name\n","\n","    # 인터뷰 사전 처리\n","    state = preProcessing_Interview(file_path)\n","    session_state[\"state\"] = state\n","    session_state[\"interview_started\"] = True\n","\n","    # 첫 질문 저장\n","    first_question = state[\"current_question\"]\n","    session_state[\"chat_history\"].append([\"🤖 AI 면접관\", first_question])\n","\n","    return session_state, session_state[\"chat_history\"]\n","\n","# 답변 처리 및 다음 질문 생성\n","def chat_interview(user_input, session_state):\n","    if not session_state[\"interview_started\"]:\n","        return session_state, \"먼저 이력서를 업로드하고 인터뷰를 시작하세요.\"\n","\n","    # (1) 사용자 답변 저장\n","    session_state[\"chat_history\"].append([\"🙋‍♂️ 지원자\", user_input])\n","    session_state[\"state\"] = update_current_answer(session_state[\"state\"], user_input)\n","\n","    # (2) Agent 실행 (평가 및 다음 질문 or 종료)\n","    session_state[\"state\"] = graph.invoke(session_state[\"state\"])\n","\n","    # (3) 종료 여부 판단\n","    if session_state[\"state\"][\"next_step\"] == \"end\":\n","        session_state[\"interview_ended\"] = True\n","        final_summary = \"✅ 인터뷰가 종료되었습니다!\\n\\n\"\n","\n","        ## 1. 수정 부분\n","        # for i, turn in enumerate(session_state[\"state\"][\"conversation\"]):\n","        #     final_summary += f\"\\n**[질문 {i+1}]** {turn['question']}\\n**[답변 {i+1}]** {turn['answer']}\\n\"\n","        #     if i < len(session_state[\"state\"][\"evaluation\"]):\n","        #         eval_result = session_state[\"state\"][\"evaluation\"][i]\n","        #         final_summary += f\"_평가 - 질문 연관성: {eval_result.질문과의_관련성}, 답변 구체성: {eval_result.답변의_구체성}_\\n\"\n","\n","        session_state[\"chat_history\"].append([\"🤖 AI 면접관\",\n","                                              session_state[\"state\"][\"feedback_report\"]])\n","        return session_state, session_state[\"chat_history\"]\n","\n","    else:\n","        next_question = session_state[\"state\"][\"current_question\"]\n","        session_state[\"chat_history\"].append([\"🤖 AI 면접관\", next_question])\n","        return session_state, session_state[\"chat_history\"]\n","\n","# Gradio 인터페이스 구성\n","with gr.Blocks() as demo:\n","    session_state = gr.State(initialize_state())\n","\n","    gr.Markdown(\"# 🤖 AI 면접관 \\n이력서를 업로드하고 인터뷰를 시작하세요!\")\n","\n","    with gr.Row():\n","        file_input = gr.File(label=\"이력서 업로드 (PDF 또는 DOCX)\")\n","        upload_btn = gr.Button(\"인터뷰 시작\")\n","\n","    chatbot = gr.Chatbot()\n","    user_input = gr.Textbox(show_label=False, placeholder=\"답변을 입력하고 Enter를 누르세요.\")\n","\n","    upload_btn.click(upload_and_initialize, inputs=[file_input, session_state], outputs=[session_state, chatbot])\n","    user_input.submit(chat_interview, inputs=[user_input, session_state], outputs=[session_state, chatbot])\n","    user_input.submit(lambda: \"\", None, user_input)\n","\n","# 실행\n","demo.launch(share=True)"],"metadata":{"id":"VvYpBoXHZfvd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747014399034,"user_tz":-540,"elapsed":120,"user":{"displayName":"김민아","userId":"03129000200387278609"}},"outputId":"4f2d74f8-6ee3-445a-a45a-7e8c4777475e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"markdown","source":["# 새 섹션"],"metadata":{"id":"D766ganD__kU"}},{"cell_type":"markdown","source":["## **3. 실행**"],"metadata":{"id":"vVw8pSQRyy73"}},{"cell_type":"code","source":["!python app.py"],"metadata":{"id":"JRnTUFUs_1f8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"db21165c-2077-4e5b-82e3-e2ea094c81e5"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["/content/app.py:702: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n","  chatbot = gr.Chatbot()\n","* Running on local URL:  http://127.0.0.1:7860\n","* Running on public URL: https://33f9212cc0fec7a44c.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jqfT1WQZV9X6","executionInfo":{"status":"aborted","timestamp":1747011411613,"user_tz":-540,"elapsed":75,"user":{"displayName":"김민아","userId":"03129000200387278609"}}},"execution_count":null,"outputs":[]}]}